{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2875c30-7a3b-4f37-b8fa-2a7b5d5ffb90",
   "metadata": {},
   "source": [
    "Створити віртуальне середовище (venv) в якому будуть встановлені всі необхідні бібліотеки та налаштування для даної лабораторної роботи"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5458b-2853-43a2-a751-72aca6c45236",
   "metadata": {},
   "source": [
    "Середовище я створив вручну, користуючись візуальним інтерфейсом Anaconda Navigator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e08ac978-a11f-44b5-8042-86edfc186110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels:\n",
      " - defaults\n",
      "Platform: win-64\n",
      "Collecting package metadata (repodata.json): ...working... done\n",
      "Solving environment: ...working... done\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirements satisfied\n",
      "\n",
      "# conda environments:\n",
      "#\n",
      "base                   D:\\Users\\Bogdan\\anaconda3\n",
      "python_3-8           * D:\\Users\\Bogdan\\anaconda3\\envs\\python_3-8\n",
      "\n",
      "* - current venv\n"
     ]
    }
   ],
   "source": [
    "!conda install pandas numpy ipython matplotlib urllib3 -y\n",
    "print(\"Requirements satisfied\")\n",
    "!conda info --envs\n",
    "print(\"* - current venv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b676a-d973-44be-9a38-655cf16e1567",
   "metadata": {},
   "source": [
    "Для кожної із адміністративних одиниць України завантажити тестові структуровані файли, що містять значення VHI-індексу. Ця процедура має бути автоматизована, параметром процедури має бути індекс (номер) області. При зберіганні файлу до його імені потрібно додати дату та час завантаження. \n",
    "Передбачити повторні запуски скрипту, довантаження нових даних та колізію даних; \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3d592f14-c713-4e2b-9c6e-fdd4d7f94b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VHI for region 1 is already up to date in VHI_data/NOAA_ID_1_2025-03-06_20-10-11.csv\n",
      "VHI for region 2 is already up to date in VHI_data/NOAA_ID_2_2025-03-06_20-10-13.csv\n",
      "VHI for region 3 is already up to date in VHI_data/NOAA_ID_3_2025-03-06_20-10-14.csv\n",
      "VHI for region 4 is already up to date in VHI_data/NOAA_ID_4_2025-03-06_20-10-16.csv\n",
      "VHI for region 5 is already up to date in VHI_data/NOAA_ID_5_2025-03-06_20-10-17.csv\n",
      "VHI for region 6 is already up to date in VHI_data/NOAA_ID_6_2025-03-06_20-10-19.csv\n",
      "VHI for region 7 is already up to date in VHI_data/NOAA_ID_7_2025-03-06_20-10-20.csv\n",
      "VHI for region 8 is already up to date in VHI_data/NOAA_ID_8_2025-03-06_20-10-22.csv\n",
      "VHI for region 9 is already up to date in VHI_data/NOAA_ID_9_2025-03-06_20-10-24.csv\n",
      "Created csv-file for VHI in path: VHI_data/NOAA_ID_10_2025-03-06_21-50-33.csv\n",
      "VHI for region 11 is already up to date in VHI_data/NOAA_ID_11_2025-03-06_20-10-27.csv\n",
      "VHI for region 12 is already up to date in VHI_data/NOAA_ID_12_2025-03-06_20-10-29.csv\n",
      "VHI for region 13 is already up to date in VHI_data/NOAA_ID_13_2025-03-06_20-10-30.csv\n",
      "VHI for region 14 is already up to date in VHI_data/NOAA_ID_14_2025-03-06_20-10-32.csv\n",
      "VHI for region 15 is already up to date in VHI_data/NOAA_ID_15_2025-03-06_20-10-33.csv\n",
      "VHI for region 16 is already up to date in VHI_data/NOAA_ID_16_2025-03-06_20-10-35.csv\n",
      "VHI for region 17 is already up to date in VHI_data/NOAA_ID_17_2025-03-06_20-10-37.csv\n",
      "VHI for region 18 is already up to date in VHI_data/NOAA_ID_18_2025-03-06_20-10-39.csv\n",
      "VHI for region 19 is already up to date in VHI_data/NOAA_ID_19_2025-03-06_20-10-41.csv\n",
      "VHI for region 20 is already up to date in VHI_data/NOAA_ID_20_2025-03-06_20-10-43.csv\n",
      "VHI for region 21 is already up to date in VHI_data/NOAA_ID_21_2025-03-06_20-10-44.csv\n",
      "VHI for region 22 is already up to date in VHI_data/NOAA_ID_22_2025-03-06_20-10-46.csv\n",
      "VHI for region 23 is already up to date in VHI_data/NOAA_ID_23_2025-03-06_20-10-48.csv\n",
      "VHI for region 24 is already up to date in VHI_data/NOAA_ID_24_2025-03-06_20-10-49.csv\n",
      "VHI for region 25 is already up to date in VHI_data/NOAA_ID_25_2025-03-06_20-10-51.csv\n",
      "VHI for region 26 is already up to date in VHI_data/NOAA_ID_26_2025-03-06_20-10-52.csv\n",
      "VHI for region 27 is already up to date in VHI_data/NOAA_ID_27_2025-03-06_20-10-54.csv\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import os\n",
    "from datetime import datetime\n",
    "import hashlib\n",
    "\n",
    "def calculate_file_hash(file_path):\n",
    "    sha256_hash = hashlib.sha256()\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        for byte_block in iter(lambda: f.read(4096), b\"\"):\n",
    "            sha256_hash.update(byte_block)\n",
    "    return sha256_hash.hexdigest()\n",
    "\n",
    "def download_data(region_ID):\n",
    "    url = f\"https://www.star.nesdis.noaa.gov/smcd/emb/vci/VH/get_TS_admin.php?country=UKR&provinceID={region_ID}&year1=1981&year2=2024&type=Mean\"\n",
    "    current_datetime = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    csv_file_path = f'{dir_for_data}/NOAA_ID_{region_ID}_{current_datetime}.csv'\n",
    "    \n",
    "    try:\n",
    "        vhi_url = urllib.request.urlopen(url)\n",
    "        # Записуємо нові дані у файл\n",
    "        with open(csv_file_path, 'wb') as new_file:\n",
    "            new_file.write(vhi_url.read())\n",
    "\n",
    "        # Обчислюємо хеш нового файлу\n",
    "        new_file_hash = calculate_file_hash(csv_file_path)\n",
    "\n",
    "        # Перевіряємо, чи існує csv-файл з ідентичним вмістом\n",
    "        region_file_found = False\n",
    "        for existing_file in os.listdir(dir_for_data):\n",
    "            existing_file_path = f\"{dir_for_data}/{existing_file}\"\n",
    "\n",
    "            if os.path.isfile(existing_file_path):\n",
    "                if existing_file_path != csv_file_path:\n",
    "                    existing_file_hash = calculate_file_hash(existing_file_path)\n",
    "\n",
    "                    if existing_file_hash == new_file_hash:\n",
    "                        print(f\"VHI for region {region_ID} is already up to date in {existing_file_path}\")\n",
    "                        os.remove(csv_file_path)  # Видаляємо новий файл, якщо знайдений файл з ідентичним хешем\n",
    "                        region_file_found = True\n",
    "                        break\n",
    "\n",
    "        # Якщо дані нові, створюємо новий файл\n",
    "        if not region_file_found:\n",
    "            print(f\"Created csv-file for VHI in path: {csv_file_path}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading VHI for region {region_ID}: {e}\")\n",
    "\n",
    "dir_for_data = \"VHI_data\"\n",
    "if not os.path.exists(dir_for_data):\n",
    "    os.makedirs(dir_for_data)\n",
    "\n",
    "# Завантажуємо дані кожної адмін. одиниці України, з індексом 1-27\n",
    "for i in range(1, 28):\n",
    "    download_data(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70026af4-7e95-41fe-aa05-a7359d9f4af1",
   "metadata": {},
   "source": [
    "Зчитати завантажені текстові файли у фрейм. Імена стовбців фрейму мають бути змістовними та легкими для сприйняття (не повинно бути спеціалізованих символів, пробілів тощо). Ця задача має бути реалізована у вигляді окремої процедури, яка на вхід приймає шлях до директорії, в якій зберігаються файли;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "22352736-91e3-4f61-b572-e5653eef7cb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Skipped file: NOAA_Ukraine.csv\n",
      "\n",
      "\n",
      "Skipped file: NOAA_Ukraine_Updated.csv\n",
      "\n",
      "Removed 2.28% corrupted data\n",
      "         Year  Week    SMN     SMT    VCI    TCI    VHI Region\n",
      "21860  1982.0   1.0  0.053  260.31  45.01  39.46  42.23      1\n",
      "21861  1982.0   2.0  0.054  262.29  46.83  31.75  39.29      1\n",
      "21862  1982.0   3.0  0.055  263.82  48.13  27.24  37.68      1\n",
      "21863  1982.0   4.0  0.053  265.33  46.09  23.91  35.00      1\n",
      "21864  1982.0   5.0  0.050  265.66  41.46  26.65  34.06      1\n",
      "...       ...   ...    ...     ...    ...    ...    ...    ...\n",
      "41529  2024.0  48.0  0.128  270.55  64.97  25.53  45.25     27\n",
      "41530  2024.0  49.0  0.115  269.06  60.12  27.24  43.68     27\n",
      "41531  2024.0  50.0  0.104  267.75  55.24  25.89  40.57     27\n",
      "41532  2024.0  51.0  0.094  266.45  51.16  24.29  37.72     27\n",
      "41533  2024.0  52.0  0.093  266.38  54.22  21.11  37.66     27\n",
      "\n",
      "[59022 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_data_from_directory(dir_for_data):\n",
    "    # Імена стовпців повинні бути зрозумілими та без спеціальних символів\n",
    "    column_names = [\"Year\", \"Week\", \"SMN\", \"SMT\", \"VCI\", \"TCI\", \"VHI\", \"Region\"]\n",
    "    combined_data = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    # Ініціалізуємо лічильники початкової кількості рядків і кінцевої\n",
    "    total_initial_rows = 0\n",
    "    total_final_rows = 0\n",
    "    \n",
    "    # Зчитаємо файли з директорії\n",
    "    filenames = os.listdir(dir_for_data)\n",
    "\n",
    "    for filename in filenames:\n",
    "        # Перевіряємо, чи є файл CSV\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(dir_for_data, filename)\n",
    "\n",
    "        # Читання CSV файлу, пропускаємо перші 2 рядки\n",
    "        df = pd.read_csv(file_path, skiprows=2, names=column_names)\n",
    "\n",
    "        # Очищення стовпця \"Year\" від небажаних тегів\n",
    "        df[\"Year\"] = df[\"Year\"].astype(str).str.replace('<tt><pre>', '').str.replace('</pre></tt>', '')\n",
    "        \n",
    "        # Перетворюємо стовпець Year на числовий тип\n",
    "        df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "        # Дістаємо Region_ID з імені файлу\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) > 2 and parts[2].isdigit():\n",
    "            region_id = int(parts[2])\n",
    "        else:\n",
    "            print(f\"\\nSkipped file: {filename}\\n\")\n",
    "            continue  # Якщо ID не є числом, пропускаємо файл\n",
    "\n",
    "        df[\"Region\"] = region_id\n",
    "\n",
    "        # Кількість початкових рядків\n",
    "        initial_rows = len(df)\n",
    "        total_initial_rows += initial_rows\n",
    "        \n",
    "        # Видаляємо записи, де у колонці VHI значення NaN\n",
    "        df = df.drop(df.loc[df['VHI'] == -1].index).dropna()\n",
    "        \n",
    "        # Кількість рядків після очищення\n",
    "        final_rows = len(df)\n",
    "        total_final_rows += final_rows\n",
    "        \n",
    "        # Об'єднуємо дані\n",
    "        combined_data = pd.concat([combined_data, df], ignore_index=True)\n",
    "            \n",
    "    # Обчислення відсотка видалених даних\n",
    "    removed_percentage = ((total_initial_rows - total_final_rows) / total_initial_rows) * 100\n",
    "    print(f\"Removed {removed_percentage:.2f}% corrupted data\\n\")\n",
    "\n",
    "    return combined_data\n",
    "\n",
    "# Завантажуємо дані з директорії\n",
    "combined_data = load_data_from_directory(dir_for_data)\n",
    "combined_data_sorted = combined_data.sort_values(by=[\"Year\", \"Region\"], ascending=[True, True])\n",
    "\n",
    "# Зберігаємо результат у CSV файл\n",
    "output_path = f\"{dir_for_data}/NOAA_Ukraine.csv\"\n",
    "combined_data_sorted.to_csv(output_path, index=False)\n",
    "\n",
    "print(combined_data_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72fe043-722b-44c4-9339-85033f862feb",
   "metadata": {},
   "source": [
    "Реалізувати окрему процедуру, яка змінить індекси областей, які використані на порталі NOAA (за англійською абеткою) на наступні, за українською (виключно старі індекси на нові):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "a0827b00-4e72-470b-923c-e6a5b71ccc0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Year  Week    SMN     SMT    VCI    TCI    VHI  Region\n",
      "32790  1982.0   1.0  0.068  263.59  63.47  28.34  45.90       1\n",
      "32791  1982.0   2.0  0.074  265.78  67.62  23.05  45.34       1\n",
      "32792  1982.0   3.0  0.076  267.19  69.37  20.40  44.88       1\n",
      "32793  1982.0   4.0  0.075  268.57  65.26  17.93  41.60       1\n",
      "32794  1982.0   5.0  0.072  269.24  58.58  20.00  39.29       1\n",
      "...       ...   ...    ...     ...    ...    ...    ...     ...\n",
      "32785  2024.0  48.0  0.158  273.77  59.36  18.43  38.89      27\n",
      "32786  2024.0  49.0  0.142  272.55  60.09  16.43  38.26      27\n",
      "32787  2024.0  50.0  0.135  272.00  63.46  11.52  37.49      27\n",
      "32788  2024.0  51.0  0.129  271.49  67.23   8.72  37.98      27\n",
      "32789  2024.0  52.0  0.125  271.07  69.11   8.23  38.67      27\n",
      "\n",
      "[59022 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# Відповідність старих індексів (NOAA) новим українським\n",
    "region_index_eng_to_ukr = {\n",
    "    1: 24,  # Cherkasy -> Черкаська\n",
    "    2: 26,  # Chernihiv -> Чернігівська\n",
    "    3: 25,  # Chernivtsi -> Чернівецька\n",
    "    4: 27,  # Crimea -> Республіка Крим\n",
    "    5: 3,   # Dnipropetrovs'k -> Дніпропетровська\n",
    "    6: 4,   # Donets'k -> Донецька\n",
    "    7: 8,   # Ivano-Frankivs'k -> Івано-Франківська\n",
    "    8: 21,  # Kharkiv -> Харківська\n",
    "    9: 22,  # Kherson -> Херсонська\n",
    "    10: 23, # Khmelnyts'kyi -> Хмельницька\n",
    "    11: 10, # Kiev -> Київська\n",
    "    12: 9,  # Kiev City -> Київ\n",
    "    13: 11, # Kirovohrad -> Кіровоградська\n",
    "    14: 12, # Luhans'k -> Луганська\n",
    "    15: 13, # L'viv -> Львівська\n",
    "    16: 14, # Mykolaiv -> Миколаївська\n",
    "    17: 15, # Odessa -> Одеська\n",
    "    18: 16, # Poltava -> Полтавська\n",
    "    19: 17, # Rivne -> Рівненська\n",
    "    20: 18, # Sevastopol' -> Севастополь\n",
    "    21: 19, # Sumy -> Сумська\n",
    "    22: 20, # Ternopil' -> Тернопільська\n",
    "    23: 6,  # Transcarpathia (Zakarpattia) -> Закарпатська\n",
    "    24: 1,  # Vinnytsia -> Вінницька\n",
    "    25: 2,  # Volyn -> Волинська\n",
    "    26: 7,  # Zaporizhzhia -> Запорізька\n",
    "    27: 5   # Zhytomyr -> Житомирська\n",
    "}\n",
    "\n",
    "def update_region_indexes(df):\n",
    "    df[\"Region\"] = df[\"Region\"].map(region_index_eng_to_ukr)\n",
    "    return df\n",
    "\n",
    "# Оновлення індексів областей\n",
    "combined_data_updated = update_region_indexes(combined_data)\n",
    "combined_data_updated_sorted = combined_data.sort_values(by=[\"Year\", \"Region\"])\n",
    "\n",
    "# Збереження оновлених даних\n",
    "combined_data_updated_sorted.to_csv(f\"{dir_for_data}/NOAA_Ukraine_Updated.csv\", index=False)\n",
    "\n",
    "# Вивід оновлених даних\n",
    "print(combined_data_updated_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22ba7ca7-312f-4813-a1e4-480b7dd146a4",
   "metadata": {},
   "source": [
    "Реалізувати процедури для формування вибірок наступного виду (включаючи елементи аналізу):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01782daa-fe8b-4385-9623-f279e5ce9759",
   "metadata": {},
   "source": [
    "o Ряд VHI для області за вказаний рік;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb3dfde1-1d12-455e-8cd8-a409d29bc151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Year  Week    VHI\n",
      "24150  1984.0   1.0  39.40\n",
      "24151  1984.0   2.0  38.43\n",
      "24152  1984.0   3.0  37.78\n",
      "24153  1984.0   4.0  37.22\n",
      "24154  1984.0   5.0  37.06\n",
      "24155  1984.0   6.0  37.09\n",
      "24156  1984.0   7.0  36.14\n",
      "24157  1984.0   8.0  37.40\n",
      "24158  1984.0   9.0  38.85\n",
      "24159  1984.0  10.0  40.04\n",
      "24160  1984.0  11.0  39.09\n",
      "24161  1984.0  12.0  39.19\n",
      "24162  1984.0  13.0  38.56\n",
      "24163  1984.0  14.0  37.93\n",
      "24164  1984.0  15.0  35.78\n",
      "24165  1984.0  16.0  35.45\n",
      "24166  1984.0  17.0  37.61\n",
      "24167  1984.0  18.0  40.66\n",
      "24168  1984.0  19.0  39.71\n",
      "24169  1984.0  20.0  39.34\n",
      "24170  1984.0  21.0  40.56\n",
      "24171  1984.0  22.0  41.67\n",
      "24172  1984.0  23.0  40.49\n",
      "24173  1984.0  24.0  39.29\n",
      "24174  1984.0  25.0  38.45\n",
      "24175  1984.0  26.0  37.94\n",
      "24176  1984.0  27.0  36.06\n",
      "24177  1984.0  28.0  34.31\n",
      "24178  1984.0  29.0  33.05\n",
      "24179  1984.0  30.0  32.43\n",
      "24180  1984.0  31.0  33.19\n",
      "24181  1984.0  32.0  33.60\n",
      "24182  1984.0  33.0  33.58\n",
      "24183  1984.0  34.0  33.51\n",
      "24184  1984.0  35.0  32.40\n",
      "24185  1984.0  36.0  28.78\n",
      "24186  1984.0  37.0  24.17\n",
      "24187  1984.0  38.0  21.53\n",
      "24188  1984.0  39.0  21.02\n",
      "24189  1984.0  40.0  20.50\n",
      "24190  1984.0  41.0  22.99\n",
      "24191  1984.0  42.0  27.34\n",
      "24192  1984.0  43.0  30.59\n",
      "24193  1984.0  44.0  34.33\n",
      "24194  1984.0  45.0  37.22\n",
      "24195  1984.0  46.0  38.30\n",
      "24196  1984.0  47.0  37.85\n",
      "24197  1984.0  48.0  37.89\n",
      "24198  1984.0  49.0  34.63\n"
     ]
    }
   ],
   "source": [
    "def get_region_VHI_in_specified_year(data, region_id, year):\n",
    "    # Фільтруємо за вказаними параметрами\n",
    "    region_data = data[(data[\"Region\"] == region_id) & (data[\"Year\"] == year)]\n",
    "    return region_data[[\"Year\", \"Week\", \"VHI\"]]\n",
    "    \n",
    "region_vhi = get_region_VHI_in_specified_year(combined_data_updated_sorted, region_id=14, year=1984)\n",
    "print(region_vhi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814b6e6f-c56e-4ae2-9acf-b662a7dd8044",
   "metadata": {},
   "source": [
    "o Пошук екстремумів (min та max) для вказаних областей та років, середнього, медіани;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ff94815f-b4fd-4c82-84a8-c8f80df323d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Region    Year  min_VHI_value  max_VHI_value  mean_VHI_value  \\\n",
      "0       1  1988.0          22.58          63.04       46.365769   \n",
      "1       1  2014.0          36.37          66.94       51.377115   \n",
      "2       2  1988.0          34.17          66.27       52.910385   \n",
      "3       2  2014.0          24.16          64.81       42.641346   \n",
      "4       3  1988.0          26.95          70.20       49.354808   \n",
      "5       3  2014.0          28.95          56.51       43.272308   \n",
      "\n",
      "   median_VHI_value  \n",
      "0            48.175  \n",
      "1            48.200  \n",
      "2            53.555  \n",
      "3            40.455  \n",
      "4            53.960  \n",
      "5            43.195  \n"
     ]
    }
   ],
   "source": [
    "def find_min_max_mean_median(data, regions, years, column):\n",
    "    if column not in data.columns:\n",
    "        raise ValueError(f\"Column '{column}' does not exist. Сhoose one of the available ones: {list(data.columns)}\")\n",
    "\n",
    "    # Фільтруємо дані за вказаними параметрами\n",
    "    filtered_data = data[(data[\"Region\"].isin(regions)) & (data[\"Year\"].isin(years))]\n",
    "\n",
    "    # За допомогою функції agg визначаємо екстремуми, середнє, медіану заданої колонки\n",
    "    result = filtered_data.groupby([\"Region\", \"Year\"])[column].agg(\n",
    "        min_value=\"min\",\n",
    "        max_value=\"max\",\n",
    "        mean_value=\"mean\",\n",
    "        median_value=\"median\"\n",
    "    ).rename(columns={\n",
    "        \"min_value\": f\"min_{column}_value\",\n",
    "        \"max_value\": f\"max_{column}_value\",\n",
    "        \"mean_value\": f\"mean_{column}_value\",\n",
    "        \"median_value\": f\"median_{column}_value\"\n",
    "    }).reset_index()\n",
    "\n",
    "    return result\n",
    "\n",
    "try:\n",
    "    extremes = find_min_max_mean_median(combined_data_updated_sorted, regions=[1, 2, 3], years=[2014, 1988], column=\"VHI\")\n",
    "    print(extremes)\n",
    "except ValueError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b4002b-ec04-40b3-85b8-4eec84892d3e",
   "metadata": {},
   "source": [
    "o Ряд VHI за вказаний діапазон років для вказаних областей;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "845351c7-284b-4046-9c1d-8a27f01ddbb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Year  Week  Region    VHI\n",
      "34404  2014.0   1.0       1  47.80\n",
      "34405  2014.0   2.0       1  50.45\n",
      "34406  2014.0   3.0       1  53.22\n",
      "34407  2014.0   4.0       1  52.93\n",
      "34408  2014.0   5.0       1  49.86\n",
      "...       ...   ...     ...    ...\n",
      "50169  2022.0  48.0       2  47.74\n",
      "50170  2022.0  49.0       2  46.93\n",
      "50171  2022.0  50.0       2  46.14\n",
      "50172  2022.0  51.0       2  47.72\n",
      "50173  2022.0  52.0       2  49.82\n",
      "\n",
      "[936 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_regions_VHI_in_specified_period(data, region_ids, start_year, end_year):\n",
    "    # Фільтруємо за вказаними параметрами\n",
    "    filtered_data = data[(data[\"Region\"].isin(region_ids)) & (data[\"Year\"] >= start_year) & (data[\"Year\"] <= end_year)]\n",
    "    return filtered_data[[\"Year\", \"Week\", \"Region\", \"VHI\"]]\n",
    "\n",
    "RegionsVHI_in_Period = get_regions_VHI_in_specified_period(combined_data_updated_sorted, region_ids=[1, 2], start_year=2014, end_year=2022)\n",
    "print(RegionsVHI_in_Period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e80c5a-9215-460c-bcd1-2b47f4e0716c",
   "metadata": {},
   "source": [
    "o Для всього набору даних виявити роки, протягом яких екстремальні посухи торкнулися більше вказаного відсотка областей по Україні (20% областей - 5 областей з 25). Повернути роки, назви областей з екстремальними посухами та значення VHI;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "de97e673-185f-4634-a0fa-c8f8fee6e4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Year  Region    VHI\n",
      "33740  2000.0       1  12.26\n",
      "33741  2000.0       1  11.28\n",
      "33742  2000.0       1  11.25\n",
      "33743  2000.0       1  11.38\n",
      "33744  2000.0       1  12.91\n",
      "33745  2000.0       1  14.20\n",
      "3135   2000.0       6  12.51\n",
      "3136   2000.0       6  10.60\n",
      "3137   2000.0       6  11.20\n",
      "3138   2000.0       6  12.32\n",
      "3139   2000.0       6  14.65\n",
      "24996  2000.0      14  13.14\n",
      "24997  2000.0      14   9.50\n",
      "24998  2000.0      14   8.14\n",
      "24999  2000.0      14   9.69\n",
      "25000  2000.0      14  11.20\n",
      "25001  2000.0      14  11.36\n",
      "25002  2000.0      14  12.77\n",
      "55601  2000.0      17  14.61\n",
      "55602  2000.0      17  11.33\n",
      "55603  2000.0      17   9.36\n",
      "55604  2000.0      17   9.45\n",
      "55605  2000.0      17   9.73\n",
      "55606  2000.0      17  11.45\n",
      "55607  2000.0      17  14.29\n",
      "5319   2000.0      20  14.89\n",
      "5320   2000.0      20  12.76\n",
      "5321   2000.0      20   7.81\n",
      "5322   2000.0      20   6.49\n",
      "5323   2000.0      20   6.58\n",
      "5324   2000.0      20   6.71\n",
      "5325   2000.0      20   7.56\n",
      "5326   2000.0      20   9.25\n",
      "5327   2000.0      20  10.94\n",
      "5328   2000.0      20  12.28\n",
      "22809  2000.0      24  14.64\n",
      "22810  2000.0      24  11.82\n",
      "22811  2000.0      24  10.81\n",
      "22812  2000.0      24  10.68\n",
      "22813  2000.0      24  12.30\n",
      "22814  2000.0      24  14.24\n"
     ]
    }
   ],
   "source": [
    "def find_extreme_droughts(data, regions_percentage=20):\n",
    "    # Визначення кількості областей\n",
    "    total_regions = len(data[\"Region\"].unique())\n",
    "    regions_count = (regions_percentage / 100) * total_regions\n",
    "\n",
    "    # Екстримальні посухи\n",
    "    extreme_droughts = data[data[\"VHI\"] <= 15]\n",
    "    \n",
    "    # Кількість областей з екстримальними посухами по рокам\n",
    "    drought_count_by_year = extreme_droughts.groupby(\"Year\")[\"Region\"].nunique()\n",
    "\n",
    "    # Вибираємо роки, де кількість областей з екстремальними посухами перевищує поріг\n",
    "    extreme_years = drought_count_by_year[drought_count_by_year >=regions_count].index\n",
    "\n",
    "    # Повертаємо відповідні дані\n",
    "    result = extreme_droughts[extreme_droughts[\"Year\"].isin(extreme_years)]\n",
    "    return result[[\"Year\", \"Region\", \"VHI\"]]\n",
    "\n",
    "extreme_droughts = find_extreme_droughts(combined_data_updated_sorted, regions_percentage=20)\n",
    "print(extreme_droughts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
